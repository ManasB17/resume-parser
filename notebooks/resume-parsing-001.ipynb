{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tika\n",
    "from tika import parser\n",
    "\n",
    "tika.initVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_resume(file_path):\n",
    "    results = parser.from_file(filename=file_path)\n",
    "    document_text = results['content']\n",
    "    return document_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "nlp = spacy.load('en_core_web_trf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extracting clean text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MYCV.docx JYOTI PRAKASH UPRETY Aspiring Data Scientist PERSONAL DETAILS Date Birth 12 03 1999 Place Birth Jhapa Civil Status Unmarried Gender Male Phone +977 9824035434 Email:Jyotiprakashuprety35@gmail.com CAREER OBJECTIVES explore analyze process complex data sets advanced querying visualization analytics tools Data Science expert provide decision support different field reaching conclusion optimize business processes taking advantage data providing new vision existing system COURSES ★ MERN Stack ○ Patan Multiple Campus ■ 06/2019 -09/2019 ★ SEO DIgital Marketing ○ Patan Multiple Campus ■ 05/2020 -07/2020 ★ Google Data Analytics ○ Coursera ■ 12/2021 Present ACHIEVEMENTS ★ Topper BCA Patan Multiple Campus couple semesters REFERENCES ★ Bhoj Raj Joshi BCA Coordinator PMC +977 9851164998 ★ Ramesh Saud Lecturer Patan Multiple Campus +977 9851164998 EDUCATION ❖ Shree Harikul Model Higher Secondary School]/SLC ➢ 2003 2015 ❖ Shree Kankai Secondary School]/+2 ➢ 2015 2017 ❖ Patan Multiple Campus]/Bachelor Computer Application(BCA ➢ 2018 Present WORK EXPERIENCE PROJECTS ❖ MOTARGADI Vehicle Management system ■ Patan Multiple Campus 08/2019–12/2019 ➢ web based project vehicle recommendation system dual project handled backend ❖ ECG Classifier Decision tree algorithm ■ Patan Multiple Campus 08/2019–12/2019 ➢ IOT based project AD8232 sensor ESP32 microcontroller Kaggle standard ECG data training model ID3 decision tree algorithm SKILLS ❖ Java- Intermediate ❖ Python- Intermediate ❖ Pandas- Beginner ❖ Numpy- Beginner ❖ SKlearn- Beginner ❖ MySQL- Intermediate ❖ Excel- Intermediate ❖ Linux- Intermediate ❖ MERN Intermediate ❖ Laravel -Intermediate'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "resume = \"jpu.pdf\"\n",
    "resume_text = extract_text_from_resume(resume)\n",
    "\n",
    "\n",
    "if resume in resume_text:\n",
    "    resume_text = resume_text.replace(filename, '')\n",
    "\n",
    "doc = nlp(resume_text)\n",
    "\n",
    "#remove file name\n",
    "# remove html tags\n",
    "text_without_html = \" \".join([token.text for token in doc if not token.is_stop and not token.is_punct])\n",
    "text_without_html\n",
    "\n",
    "# remove unwanted white spaces\n",
    "\n",
    "clean_text = re.sub('\\s+', ' ', text_without_html).strip()\n",
    "clean_text\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Remove metadata and give a clean code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (953 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Riya Lamichhane Balaju,Kathmandu|9860831724|lcsmriti@gmail.com EDUCATION Tribhuwan University Ghantaghar Kathmandu Bachelor Science Microbiology 2017 2022 Percentage aggregate 75.5 Courses Microbiology Chemistry Biochemistry Microbial biotechnology Applied Statistics Molecular Cell biology Immunology Computational course Thesis Antibacterial activity Nepalese Medicinal plants different bacterial isolates Sainik Awasiya Mahavidhyalaya Sallaghari Bhaktapur High school 2015 2017 SKILLS \\uf0b7 Core skills Routine microbiological techniques isolation culture enumeration molecular techniques DNA isolation extraction PCR gel electrophoresis flow cytometry research methodology research writing \\uf0b7 Technical skills Microsoft Word PowerPoint Excel \\uf0b7 Programming language Python python packages Numpy Pandas Matplotlib ML models R(beginner \\uf0b7 Tools git GitHub Jupyter \\uf0b7 Soft skills Teamwork Time management problem solving ACADEMIC EXPERIENCE Research Intern Center Health Disease Studies(CHDS Nepal Apr 2022 present \\uf0b7 Assumed role field enumerator collect data research titled Assess Satisfaction Clients Utilizing Rehabilitation Services Physical Rehabilitation Units Nepal EDCD program Government Nepal funded USAID Handicapped International HI \\uf0b7 Responsible performing routine microbiological tests molecular assays different biological samples \\uf0b7 Assisted documentation writing SOP sections laboratory Med micro Research Laboratory Babarmahal Kathmandu Jan2022 Feb2022 \\uf0b7 Assisted enumeration serial tube dilution method isolation E. coli Bagmati water samples collected different sites Kathmandu valley VOLUNTEER EXPERIENCE EXTRA CURRICULAR ACTIVITIES \\uf0b7 Volunteered participate awareness program held organization called Alliance Antimicrobial Resistance(AAMR goal program raise awareness increased global antimicrobial resistance high school students Takshashila academy \\uf0b7 week long pneumonia awareness campaign targeted expectant mothers conducted November 7 November 12 occasion World Pneumonia Day 2022 collaboration Paropakar Maternity Women Hospital Thapathali Kathmandu funded Merieux Foundation \\uf0b7 General participation DNA day organized Biotechnology Society Nepal(BSN April 2022 \\uf0b7 Participated hult prize competition 2022 conducted campus team able bag second prize ATTENDED CONFERENCE Poster presenter 9th National Conference Science Technology held National Academy Science Technology NAST June 26 June 28 2022'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tika\n",
    "from tika import parser\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Load the model\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "\n",
    "def extract_text_from_resume(file_path):\n",
    "    # Extract text from PDF file\n",
    "    results = parser.from_file(filename=file_path)\n",
    "    document_text = results['content']\n",
    "    \n",
    "    # Remove metadata from extracted text\n",
    "    document_text = remove_metadata(document_text)\n",
    "    \n",
    "    return document_text\n",
    "\n",
    "def remove_metadata(text):\n",
    "    # Define regular expressions to match metadata and unwanted generic strings\n",
    "    regex_list = []\n",
    "    # regex_list = [\n",
    "    #     r'^Title:.*$',\n",
    "    #     r'^Author:.*$',\n",
    "    #     r'^CreationDate:.*$',\n",
    "    #     r'^ModDate:.*$',\n",
    "    #     r'^Producer:.*$',\n",
    "    #     r'^Keywords:.*$',\n",
    "    #     r'^Subject:.*$',\n",
    "    #     r'^Content-Type:.*$',\n",
    "    #     r'^Resume.*$',\n",
    "    #     r'^CV.*$',\n",
    "    #     r'.*MYCV.*',\n",
    "    #     r'.*myresume.*'\n",
    "    #     r'.*Curriculum_Vitae.*'\n",
    "    # ]\n",
    "    \n",
    "    # Remove matching patterns from the text\n",
    "    for regex in regex_list:\n",
    "        text = re.sub(regex, '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "resume = \"rl.pdf\"\n",
    "resume_text = extract_text_from_resume(resume)\n",
    "\n",
    "doc = nlp(resume_text)\n",
    "\n",
    "#remove file name\n",
    "# remove html tags\n",
    "text_without_html = \" \".join([token.text for token in doc if not token.is_stop and not token.is_punct])\n",
    "text_without_html\n",
    "\n",
    "# remove unwanted white spaces\n",
    "\n",
    "clean_text = re.sub('\\s+', ' ', text_without_html).strip()\n",
    "clean_text\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extracting fields from the documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Riya Lamichhane', 'Tribhuwan University', 'University Ghantaghar', 'Ghantaghar Kathmandu', 'Kathmandu Bachelor', 'Bachelor Science', 'Science Microbiology', 'Sainik Awasiya', 'Awasiya Mahavidhyalaya', 'Mahavidhyalaya Sallaghari', 'Sallaghari Bhaktapur', 'Bhaktapur High', 'Microsoft Word', 'Word PowerPoint', 'PowerPoint Excel', 'Numpy Pandas', 'Pandas Matplotlib', 'ACADEMIC EXPERIENCE', 'EXPERIENCE Research', 'Research Intern', 'Intern Center', 'Center Health', 'Health Disease', 'Disease Studies(CHDS', 'Studies(CHDS Nepal', 'Nepal Apr', 'Assess Satisfaction', 'Satisfaction Clients', 'Rehabilitation Services', 'Services Physical', 'Physical Rehabilitation', 'Rehabilitation Units', 'Units Nepal', 'Nepal EDCD', 'Government Nepal', 'USAID Handicapped', 'Handicapped International', 'International HI', 'Research Laboratory', 'Laboratory Babarmahal', 'Babarmahal Kathmandu', 'Alliance Antimicrobial', 'Antimicrobial Resistance(AAMR', 'World Pneumonia', 'Pneumonia Day', 'Paropakar Maternity', 'Maternity Women', 'Women Hospital', 'Hospital Thapathali', 'Thapathali Kathmandu', 'Merieux Foundation', 'Biotechnology Society', 'Society Nepal(BSN', 'Nepal(BSN April', 'National Conference', 'Conference Science', 'Science Technology', 'National Academy', 'Academy Science', 'Science Technology', 'Technology NAST', 'NAST June']\n"
     ]
    }
   ],
   "source": [
    "# extracting names form extracted text\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# loading pre-trained model\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "\n",
    "# initializing matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# def on_match(matcher, doc, id, matches):\n",
    "#     print('Matched!', matches)\n",
    "    \n",
    "def extract_name(txt):\n",
    "    pattern = [[{'POS': 'PROPN'}, {'POS': 'PROPN'}]]\n",
    "\n",
    "    matcher.add(\"FullName\", pattern)\n",
    "\n",
    "    doc = nlp(clean_text)\n",
    "    matches = matcher(doc)\n",
    "    names = []\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end].text\n",
    "        names.append(span)\n",
    "    return names\n",
    "name = extract_name(clean_text)\n",
    "print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Riya Lamichhane Balaju,Kathmandu|9860831724|lcsmriti@gmail.com\n"
     ]
    }
   ],
   "source": [
    "# extract name\n",
    "import spacy\n",
    "\n",
    "def extract_name(text):\n",
    "    # Load the English model with the transformer architecture\n",
    "    nlp = spacy.load('en_core_web_trf')\n",
    "    \n",
    "    # Process the text with spaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Initialize an empty dictionary to store the extracted names\n",
    "    names = {\n",
    "        'first_name': '',\n",
    "        'middle_name': '',\n",
    "        'last_name': ''\n",
    "    }\n",
    "    \n",
    "    # Look for entities in the text that are labeled as a person (PERSON)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'PERSON':\n",
    "            # Split the entity text into tokens and determine the first, middle, and last names\n",
    "            tokens = ent.text.split()\n",
    "            if len(tokens) == 1:\n",
    "                # If there is only one token, assume it is the first name\n",
    "                names['first_name'] = tokens[0]\n",
    "            elif len(tokens) == 2:\n",
    "                # If there are two tokens, assume the first is the first name and the second is the last name\n",
    "                names['first_name'] = tokens[0]\n",
    "                names['last_name'] = tokens[1]\n",
    "            elif len(tokens) == 3:\n",
    "                # If there are three tokens, assume the first is the first name, the second is the middle name, and the third is the last name\n",
    "                names['first_name'] = tokens[0]\n",
    "                names['middle_name'] = tokens[1]\n",
    "                names['last_name'] = tokens[2]\n",
    "            else:\n",
    "                # If there are more than three tokens, assume the last three are the middle and last name\n",
    "                names['first_name'] = tokens[0]\n",
    "                names['middle_name'] = ' '.join(tokens[1:-1])\n",
    "                names['last_name'] = tokens[-1]\n",
    "                \n",
    "            break\n",
    "    \n",
    "    return names\n",
    "\n",
    "names = extract_name(clean_text)\n",
    "if names['middle_name'] == '':\n",
    "     print(names['first_name'], names['last_name'])\n",
    "else:\n",
    "    print(names['first_name'], names['middle_name'],names['last_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'phone': ['9860831724'], 'email': ['lcsmriti@gmail.com']}\n"
     ]
    }
   ],
   "source": [
    "# extract contact details\n",
    "def extract_contact_info(text):\n",
    "    # Extract phone number using regular expression\n",
    "    phone_regex = r'\\b(?:\\d[ -.]*){9,}\\b'\n",
    "    phone_number = re.findall(phone_regex, text)\n",
    "    \n",
    "    # Extract email address using regular expression\n",
    "    email_regex = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "    email = re.findall(email_regex, text)\n",
    "        \n",
    "    contact_info = {\n",
    "        'phone': phone_number,\n",
    "        'email': email\n",
    "    }\n",
    "    \n",
    "    return contact_info\n",
    "contact = extract_contact_info(clean_text)\n",
    "print(contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MYCV.docx\n",
      "JYOTI\n",
      "PRAKASH\n",
      "UPRETY\n",
      "Aspiring\n",
      "Data\n",
      "Scientist\n",
      "PERSONAL\n",
      "DETAILS\n",
      "Date\n",
      "Birth\n",
      "12\n",
      "03\n",
      "1999\n",
      "Place\n",
      "Birth\n",
      "Jhapa\n",
      "Civil\n",
      "Status\n",
      "Unmarried\n",
      "Gender\n",
      "Male\n",
      "Phone\n",
      "+977\n",
      "9824035434\n",
      "Email:Jyotiprakashuprety35@gmail.com\n",
      "CAREER\n",
      "OBJECTIVES\n",
      "explore\n",
      "analyze\n",
      "process\n",
      "complex\n",
      "data\n",
      "sets\n",
      "advanced\n",
      "querying\n",
      "visualization\n",
      "analytics\n",
      "tools\n",
      "Data\n",
      "Science\n",
      "expert\n",
      "provide\n",
      "decision\n",
      "support\n",
      "different\n",
      "field\n",
      "reaching\n",
      "conclusion\n",
      "optimize\n",
      "business\n",
      "processes\n",
      "taking\n",
      "advantage\n",
      "data\n",
      "providing\n",
      "new\n",
      "vision\n",
      "existing\n",
      "system\n",
      "COURSES\n",
      "★\n",
      "MERN\n",
      "Stack\n",
      "○\n",
      "Patan\n",
      "Multiple\n",
      "Campus\n",
      "■\n",
      "06/2019\n",
      "-09/2019\n",
      "★\n",
      "SEO\n",
      "DIgital\n",
      "Marketing\n",
      "○\n",
      "Patan\n",
      "Multiple\n",
      "Campus\n",
      "■\n",
      "05/2020\n",
      "-07/2020\n",
      "★\n",
      "Google\n",
      "Data\n",
      "Analytics\n",
      "○\n",
      "Coursera\n",
      "■\n",
      "12/2021\n",
      "Present\n",
      "ACHIEVEMENTS\n",
      "★\n",
      "Topper\n",
      "BCA\n",
      "Patan\n",
      "Multiple\n",
      "Campus\n",
      "couple\n",
      "semesters\n",
      "REFERENCES\n",
      "★\n",
      "Bhoj\n",
      "Raj\n",
      "Joshi\n",
      "BCA\n",
      "Coordinator\n",
      "PMC\n",
      "+977\n",
      "9851164998\n",
      "★\n",
      "Ramesh\n",
      "Saud\n",
      "Lecturer\n",
      "Patan\n",
      "Multiple\n",
      "Campus\n",
      "+977\n",
      "9851164998\n",
      "EDUCATION\n",
      "❖\n",
      "Shree\n",
      "Harikul\n",
      "Model\n",
      "Higher\n",
      "Secondary\n",
      "School]/SLC\n",
      "➢\n",
      "2003\n",
      "2015\n",
      "❖\n",
      "Shree\n",
      "Kankai\n",
      "Secondary\n",
      "School]/+2\n",
      "➢\n",
      "2015\n",
      "2017\n",
      "❖\n",
      "Patan\n",
      "Multiple\n",
      "Campus]/Bachelor\n",
      "Computer\n",
      "Application(BCA\n",
      "➢\n",
      "2018\n",
      "Present\n",
      "WORK\n",
      "EXPERIENCE\n",
      "PROJECTS\n",
      "❖\n",
      "MOTARGADI\n",
      "Vehicle\n",
      "Management\n",
      "system\n",
      "■\n",
      "Patan\n",
      "Multiple\n",
      "Campus\n",
      "08/2019–12/2019\n",
      "➢\n",
      "web\n",
      "based\n",
      "project\n",
      "vehicle\n",
      "recommendation\n",
      "system\n",
      "dual\n",
      "project\n",
      "handled\n",
      "backend\n",
      "❖\n",
      "ECG\n",
      "Classifier\n",
      "Decision\n",
      "tree\n",
      "algorithm\n",
      "■\n",
      "Patan\n",
      "Multiple\n",
      "Campus\n",
      "08/2019–12/2019\n",
      "➢\n",
      "IOT\n",
      "based\n",
      "project\n",
      "AD8232\n",
      "sensor\n",
      "ESP32\n",
      "microcontroller\n",
      "Kaggle\n",
      "standard\n",
      "ECG\n",
      "data\n",
      "training\n",
      "model\n",
      "ID3\n",
      "decision\n",
      "tree\n",
      "algorithm\n",
      "SKILLS\n",
      "❖\n",
      "Java-\n",
      "Intermediate\n",
      "❖\n",
      "Python-\n",
      "Intermediate\n",
      "❖\n",
      "Pandas-\n",
      "Beginner\n",
      "❖\n",
      "Numpy-\n",
      "Beginner\n",
      "❖\n",
      "SKlearn-\n",
      "Beginner\n",
      "❖\n",
      "MySQL-\n",
      "Intermediate\n",
      "❖\n",
      "Excel-\n",
      "Intermediate\n",
      "❖\n",
      "Linux-\n",
      "Intermediate\n",
      "❖\n",
      "MERN\n",
      "Intermediate\n",
      "❖\n",
      "Laravel\n",
      "-Intermediate\n"
     ]
    }
   ],
   "source": [
    "# tokenization\n",
    "def tokenize(txt):\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_trf\")\n",
    "    doc = nlp(clean_text)\n",
    "\n",
    "    for token in doc:\n",
    "        print(token.text)\n",
    "tokenize(clean_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform data annotation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
